{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import sys\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import pickle\n",
    "import cleaner\n",
    "import augmenter\n",
    "import spellbuilder\n",
    "from spellhelper import Spellhelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(messages_filepath, categories_filepath):\n",
    "    '''\n",
    "    Input message and category data file paths\n",
    "    return merged dataframe of the two files\n",
    "    '''\n",
    "    # load\n",
    "    df_mess = pd.read_csv(messages_filepath)\n",
    "    df_cat = pd.read_csv(categories_filepath)\n",
    "\n",
    "    # merge\n",
    "    df = df_mess[['id','message']].merge(df_cat, left_on='id', right_on='id')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "messages_filepath = 'messages.csv'\n",
    "categories_filepath = 'categories.csv'\n",
    "print('loading...')\n",
    "df = load_data(messages_filepath, categories_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(df):\n",
    "    '''\n",
    "    input merged dataframe\n",
    "    determine categorys\n",
    "    format category columns\n",
    "    remove duplicates\n",
    "    drop extraneous class\n",
    "    return formatted df\n",
    "    '''\n",
    "    # category column names\n",
    "    row = df.categories[0]\n",
    "    category_colnames = [s[:-2] for s in row.split(';')]\n",
    "\n",
    "    # format category columns\n",
    "    df_form = pd.DataFrame()\n",
    "    for i, nrow in df.iterrows():\n",
    "        df_form[nrow['id']] = [int(s[-1]) for s in df.categories[i].split(';')]\n",
    "    df_form = df_form.transpose().reset_index().rename(columns={'index':'id'})\n",
    "    df_form.columns = ['id'] + category_colnames\n",
    "    df = df.merge(df_form, left_on='id', right_on='id')\n",
    "    df = df.drop(['categories'], axis=1)\n",
    "\n",
    "    # remove duplicates\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # drop rows with NaN's for emergent cases\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # drop related category 2's\n",
    "    df.drop(df[df['related']==2].index, inplace = True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format\n",
    "print('formatting...')\n",
    "df = format_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spell utility build\n",
    "print('spell_corrections...')\n",
    "fd_file, lu_file = spellbuilder.BuildFiles(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_file = 'freq_dict.txt'\n",
    "lu_file = 'lookup_dict.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean and simulate\n",
    "print('cleaning and simulating...')\n",
    "augmenter.cleaner.speller = Spellhelper(fd_file)\n",
    "with open(lu_file, 'rb') as handle:\n",
    "    augmenter.cleaner.corr_dict = pickle.load(handle)\n",
    "dfc, dfv, dft, dfa = augmenter.simulate(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Truncate(text, length=501):\n",
    "    '''\n",
    "    input string and trim length\n",
    "    strip and rejoin\n",
    "    trim to nearest word if too long\n",
    "    return truncated cleaned string\n",
    "    '''\n",
    "    strip = text.rstrip()\n",
    "    if len(strip) < length:\n",
    "        clean = ' '.join(strip.split())\n",
    "                         \n",
    "    else:                \n",
    "        tokens = strip[:length + 1].split()\n",
    "        clean = ' '.join(tokens[0:-1])\n",
    "                         \n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(df, database_filename):\n",
    "    '''\n",
    "    input cleaned dataframe and database name\n",
    "    write cleaned dataframe to database table named MessCatRaw\n",
    "    return none\n",
    "    '''\n",
    "    db_path = 'sqlite:///' + database_filename\n",
    "    engine = create_engine(db_path)\n",
    "    df.to_sql('MessCatRaw', engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('finishing...')\n",
    "# join\n",
    "df_all = pd.concat([dfc, dfa], axis = 0)\n",
    "# add validation and simulation flags\n",
    "df_all['val'] = df_all.index.isin(dfv.index)\n",
    "df_all['sim'] = df_all.index.isin(dfa.index)\n",
    "# trim\n",
    "df_all['message'] = df_all['message'].apply(Truncate)\n",
    "df_all.drop(df_all[df_all['message'].str.len()<=27].index, inplace = True)\n",
    "# save\n",
    "database_filepath = 'DisasterResponse.db'\n",
    "save_data(df_all, database_filepath)  \n",
    "print('cleaned data saved to database!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import process_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run process_data messages.csv categories.csv DisasterResponse.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (datasci)",
   "language": "python",
   "name": "datasci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
